{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9197b396-152c-42a5-bc97-cb9b6b2c09ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset names: ['T2_DS10']\n",
      "\n",
      "Processing dataset: T2_DS10\n",
      "  Feature Selection Method: MLPSHAP\n",
      "hp_sets [(32, 64, 0.01), (32, 64, 0.001), (32, 128, 0.01), (32, 128, 0.001), (64, 64, 0.01), (64, 64, 0.001), (64, 128, 0.01), (64, 128, 0.001)]\n",
      "hp_set: 0\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 0 ,best_val_loss(MAE): 0.09226505755520377, Took: 2.70mins\n",
      "best set and model so far (32, 64, 0.01) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 1\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 1 ,best_val_loss(MAE): 0.03466146076281898, Took: 2.57mins\n",
      "best set and model so far (32, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 2\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 2 ,best_val_loss(MAE): 0.07877486094188052, Took: 2.85mins\n",
      "best set and model so far (32, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 3\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 3 ,best_val_loss(MAE): 0.03652713496417722, Took: 2.77mins\n",
      "best set and model so far (32, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 4\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 4 ,best_val_loss(MAE): 0.05868445841063346, Took: 1.54mins\n",
      "best set and model so far (32, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 5\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 5 ,best_val_loss(MAE): 0.01517398331669115, Took: 1.51mins\n",
      "best set and model so far (64, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 6\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Set 6 ,best_val_loss(MAE): 0.042214585978183006, Took: 1.65mins\n",
      "best set and model so far (64, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "hp_set: 7\n",
      "Epoch 0\n",
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 400 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 7 ,best_val_loss(MAE): 0.020309760164292086, Took: 1.64mins\n",
      "best set and model so far (64, 64, 0.001) SimpleMLP(\n",
      "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Best hp_set: (64, 64, 0.001)\n",
      "Explainer Type: <class 'shap.explainers._kernel.KernelExplainer'>\n",
      "Explainer Attributes: {'link': <shap.utils._legacy.IdentityLink object at 0x000001CD0F9AB790>, 'keep_index': False, 'keep_index_ordered': False, 'model': <shap.utils._legacy.Model object at 0x000001CD0CB84CD0>, 'data': <shap.utils._legacy.DenseData object at 0x000001CD18CA8250>, 'N': 400, 'P': 112, 'linkfv': <numpy.vectorize object at 0x000001CD18CF3310>, 'nsamplesAdded': 0, 'nsamplesRun': 0, 'fnull': array([40.04491307]), 'expected_value': array([40.04491307]), 'vector_out': True, 'D': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe6b8a0c085437d9f7b362dc56157c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature Selection Method: LC\n",
      "  Feature Selection Method: MI\n",
      "  Feature Selection Method: DT\n",
      "\n",
      "Feature selection completed and saved to: ./chosen_features_MLPSHAP_v2/Kelmarsh_Ordered_features_vG_T2_DS10.pkl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Local imports\n",
    "from Utils.utils import MinMaxScale_datasets\n",
    "from Utils.feature_selection_methods import (\n",
    "    select_n_features_LC, select_n_features_MI,\n",
    "    select_n_features_DT, select_n_features_MLPSHAP\n",
    ")\n",
    "\n",
    "# -------------------------- Configuration -------------------------- #\n",
    "farm = 'Kelmarsh'\n",
    "target_feature = 'Generator bearing rear temperature (Â°C)'\n",
    "\n",
    "# -------------------------- Load Data -------------------------- #\n",
    "with open(f'./1_healthy_datasets/{farm}_HealthyDatasets.pkl', 'rb') as f:\n",
    "    healthy_datasets = pickle.load(f)\n",
    "\n",
    "# Normalize datasets (excluding target variable)\n",
    "healthy_datasets = MinMaxScale_datasets(healthy_datasets, target_feature)\n",
    "\n",
    "# Select datasets to process\n",
    "dataset_names = [list(healthy_datasets.keys())[0]]\n",
    "print('Dataset names:', dataset_names)\n",
    "\n",
    "# Define feature selection methods\n",
    "fs_methods = {\n",
    "    'MLPSHAP': select_n_features_MLPSHAP,\n",
    "    'LC': select_n_features_LC,\n",
    "    'MI': select_n_features_MI,\n",
    "    'DT': select_n_features_DT\n",
    "}\n",
    "\n",
    "# Output directory: where cleaned files will be saved\n",
    "save_dir = './2_ordered_inputs'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# -------------------------- Feature Selection Loop -------------------------- #\n",
    "chosen_features_dict = {}\n",
    "start_time = time.time()\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f'\\nProcessing dataset: {dataset_name}')\n",
    "\n",
    "    # Load split sets\n",
    "    train_set = healthy_datasets[dataset_name]['train']\n",
    "    valid_set = healthy_datasets[dataset_name]['valid']\n",
    "    test_set = healthy_datasets[dataset_name]['test']\n",
    "\n",
    "    total_features = train_set.shape[1]\n",
    "\n",
    "    for fs_method, selector in fs_methods.items():\n",
    "        print(f'  Feature Selection Method: {fs_method}')\n",
    "\n",
    "        # Copy data\n",
    "        selector_set = train_set.copy()\n",
    "        valid_copy = valid_set.copy()\n",
    "\n",
    "        # Remove rows with NaNs from selector set\n",
    "        nan_rows = selector_set.isna().any(axis=1)\n",
    "        selector_set = selector_set.loc[~nan_rows]\n",
    "\n",
    "        if fs_method == 'MLPSHAP':\n",
    "            # Perform feature selection (using all features for full ranking)\n",
    "            chosen_features, weights = selector(selector_set, valid_copy, target_feature, total_features, epochs=200, background_samples = 400)\n",
    "        else:\n",
    "            chosen_features, weights = selector(selector_set, target_feature, total_features)          \n",
    "\n",
    "        # Store selected features\n",
    "        key = f'{dataset_name}_{fs_method}'\n",
    "        chosen_features_dict[key] = list(chosen_features)\n",
    "\n",
    "    # -------------------------- Save Results -------------------------- #\n",
    "    with open(f'{save_dir}/{farm}_ordered_inputs.pkl', 'wb') as f:\n",
    "        pickle.dump(chosen_features_dict, f)\n",
    "    \n",
    "    print(f'\\nFeature selection completed and saved to: {output_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
